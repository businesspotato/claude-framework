#!/bin/bash

# Token Tracking Hook for Claude Code
# Tracks API token usage and costs for optimization
# Part of the token optimization system to reduce API costs by 70%

TOOL="$1"
RESULT="$2"
TIMESTAMP=$(date +%s)
DB_PATH="data/database/cards.db"
METRICS_LOG=".claude/metrics/token-usage.jsonl"

# Ensure metrics directory exists
mkdir -p .claude/metrics

# Function to estimate tokens based on response size
estimate_tokens() {
  local text="$1"
  # Rough estimate: 1 token per 4 characters
  echo $((${#text} / 4))
}

# Function to estimate cost based on service and tokens
estimate_cost() {
  local service="$1"
  local tokens="$2"
  case "$service" in
    azure_ocr)
      # Azure OCR: ~$0.0001 per token (estimate)
      echo "scale=6; $tokens * 0.0001" | bc
      ;;
    azure_vision)
      # Azure Vision: ~$0.00015 per token (estimate)
      echo "scale=6; $tokens * 0.00015" | bc
      ;;
    ebay)
      # eBay API: Generally free within limits
      echo "0.0"
      ;;
    cloudinary)
      # Cloudinary: Bandwidth costs
      echo "scale=6; $tokens * 0.00001" | bc
      ;;
    *)
      echo "0.0"
      ;;
  esac
}

# Track token usage based on tool type
case "$TOOL" in
  mcp__cloudinary__*)
    SERVICE="cloudinary"
    ENDPOINT="${TOOL#mcp__cloudinary__}"
    TOKENS=$(estimate_tokens "$RESULT")
    COST=$(estimate_cost "$SERVICE" "$TOKENS")
    CACHE_HIT=0

    # Log to database
    sqlite3 "$DB_PATH" "INSERT INTO api_metrics (timestamp, service, endpoint, tokens_used, estimated_cost, cache_hit, batch_size) VALUES ($TIMESTAMP, '$SERVICE', '$ENDPOINT', $TOKENS, $COST, $CACHE_HIT, 1)"

    # Log to JSONL
    echo "{\"timestamp\":$TIMESTAMP,\"service\":\"$SERVICE\",\"endpoint\":\"$ENDPOINT\",\"tokens\":$TOKENS,\"cost\":$COST,\"cache_hit\":false}" >> "$METRICS_LOG"
    ;;

  mcp__serena__read_file|mcp__serena__*)
    # Local operations, no external tokens
    SERVICE="local"
    ENDPOINT="${TOOL#mcp__serena__}"

    # Log to database (no tokens, just tracking)
    sqlite3 "$DB_PATH" "INSERT INTO api_metrics (timestamp, service, endpoint, tokens_used, estimated_cost, cache_hit, response_time_ms) VALUES ($TIMESTAMP, '$SERVICE', '$ENDPOINT', 0, 0.0, 1, 1)"
    ;;

  WebFetch|mcp__fetch__*)
    SERVICE="web_fetch"
    ENDPOINT="${TOOL#mcp__fetch__}"
    TOKENS=$(estimate_tokens "$RESULT")
    COST=0.0
    CACHE_HIT=0

    # Log to database
    sqlite3 "$DB_PATH" "INSERT INTO api_metrics (timestamp, service, endpoint, tokens_used, estimated_cost, cache_hit, batch_size) VALUES ($TIMESTAMP, '$SERVICE', '$ENDPOINT', $TOKENS, $COST, $CACHE_HIT, 1)"

    # Log to JSONL
    echo "{\"timestamp\":$TIMESTAMP,\"service\":\"$SERVICE\",\"endpoint\":\"$ENDPOINT\",\"tokens\":$TOKENS,\"cost\":$COST,\"cache_hit\":false}" >> "$METRICS_LOG"
    ;;

  mcp__zen__*)
    SERVICE="zen"
    ENDPOINT="${TOOL#mcp__zen__}"
    TOKENS=$(estimate_tokens "$RESULT")
    COST=0.0
    CACHE_HIT=0

    # Log to database
    sqlite3 "$DB_PATH" "INSERT INTO api_metrics (timestamp, service, endpoint, tokens_used, estimated_cost, cache_hit, batch_size) VALUES ($TIMESTAMP, '$SERVICE', '$ENDPOINT', $TOKENS, $COST, $CACHE_HIT, 1)"
    ;;

  Read|Write|Edit|MultiEdit)
    # File operations - track but no external tokens
    SERVICE="file_ops"
    ENDPOINT="$TOOL"

    sqlite3 "$DB_PATH" "INSERT INTO api_metrics (timestamp, service, endpoint, tokens_used, estimated_cost, cache_hit, response_time_ms) VALUES ($TIMESTAMP, '$SERVICE', '$ENDPOINT', 0, 0.0, 1, 1)"
    ;;

  Bash)
    # Shell commands - check if it's an API call
    if [[ "$RESULT" == *"curl"* ]] || [[ "$RESULT" == *"wget"* ]]; then
      SERVICE="external_api"
      TOKENS=$(estimate_tokens "$RESULT")
      sqlite3 "$DB_PATH" "INSERT INTO api_metrics (timestamp, service, endpoint, tokens_used, estimated_cost, cache_hit, batch_size) VALUES ($TIMESTAMP, '$SERVICE', 'bash_curl', $TOKENS, 0.0, 0, 1)"
    fi
    ;;
esac

# Check for high usage and alert
FIVE_MIN_AGO=$((TIMESTAMP - 300))
RECENT_COUNT=$(sqlite3 "$DB_PATH" "SELECT COUNT(*) FROM api_metrics WHERE timestamp > $FIVE_MIN_AGO AND cache_hit = 0 AND service NOT IN ('local', 'file_ops')")
RECENT_TOKENS=$(sqlite3 "$DB_PATH" "SELECT COALESCE(SUM(tokens_used), 0) FROM api_metrics WHERE timestamp > $FIVE_MIN_AGO")

if [ "$RECENT_COUNT" -gt 20 ]; then
  echo "{\"warning\": \"High API usage detected: $RECENT_COUNT external calls in last 5 minutes\"}"
fi

if [ "$RECENT_TOKENS" -gt 5000 ]; then
  echo "{\"warning\": \"High token consumption: $RECENT_TOKENS tokens in last 5 minutes\"}"
fi

# Daily summary (run once per day)
LAST_SUMMARY_FILE=".claude/metrics/last_summary_timestamp"
LAST_SUMMARY=0
if [ -f "$LAST_SUMMARY_FILE" ]; then
  LAST_SUMMARY=$(cat "$LAST_SUMMARY_FILE")
fi

DAYS_SINCE_SUMMARY=$(( (TIMESTAMP - LAST_SUMMARY) / 86400 ))
if [ "$DAYS_SINCE_SUMMARY" -ge 1 ]; then
  # Generate daily summary
  DAY_AGO=$((TIMESTAMP - 86400))

  SUMMARY=$(sqlite3 "$DB_PATH" << EOF
.mode json
SELECT
  service,
  COUNT(*) as total_calls,
  SUM(tokens_used) as total_tokens,
  ROUND(SUM(estimated_cost), 4) as total_cost,
  ROUND(100.0 * SUM(CASE WHEN cache_hit THEN 1 ELSE 0 END) / COUNT(*), 2) as cache_hit_rate
FROM api_metrics
WHERE timestamp > $DAY_AGO
GROUP BY service
ORDER BY total_tokens DESC;
EOF
)

  if [ -n "$SUMMARY" ]; then
    echo "$SUMMARY" > ".claude/metrics/daily_summary_$(date +%Y%m%d).json"
    echo "$TIMESTAMP" > "$LAST_SUMMARY_FILE"
  fi
fi